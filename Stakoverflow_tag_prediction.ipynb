{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stakoverflow_tag_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sweetydutta8/Python-and-Machine-Learning/blob/master/Stakoverflow_tag_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAoJSclG5aAP"
      },
      "source": [
        "Stack Overflow is the largest, most trusted online community for developers to learn, share their programming knowledge, and build their careers.\n",
        "Stack Overflow is something which every programmer use one way or another. Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers. It features questions and answers on a wide range of topics in computer programming. The website serves as a platform for users to ask and answer questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpV1vXH560b7"
      },
      "source": [
        "Link to dataset :  https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8nU7bAq460A"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "from wordcloud import WordCloud\n",
        "from sqlalchemy import create_engine # database connection\n",
        "from datetime import datetime\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "DATAPATH = \"../Data/\"\n",
        "DATA_DB = \"TRAIN.db\"\n",
        "DATA_CSV = \"TRAIN.csv\"\n",
        "DATA_DB_DEDUP = \"TRAIN_NEW.db\"\n",
        "DATA_PROCESSED = \"PROCESSED.DB\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqQ8xtgo6_il"
      },
      "source": [
        "if not os.path.isfile(os.path.join(DATAPATH, DATA_DB)):\n",
        "    start = datetime.now()\n",
        "    #this sqlalchemy create_engine creates an in-memory SQLite database.\n",
        "    engine = create_engine(\"sqlite:///\"+os.path.join(DATAPATH, DATA_DB)) #https://docs.sqlalchemy.org/en/13/core/engines.html\n",
        "    chunksize = 150\n",
        "    cnt = 0\n",
        "    for rows in pd.read_csv(os.path.join(DATAPATH, DATA_CSV), names = [\"Id\", \"Title\", \"Body\", \"Tags\"], chunksize = chunksize, iterator = True):\n",
        "        cnt+=1\n",
        "        rows.to_sql('Rows', engine, if_exists='append', index = False)\n",
        "        if cnt % 1000 == 0:\n",
        "            print(\"{} rows written\".format(cnt*chunksize))\n",
        "    print(\"Time taken to run this cell :\", datetime.now() - start)\n",
        "    \n",
        "#Here above what we are doing is that, first we have created an in memory sqlite database using the line: \n",
        "#\"create_engine(\"sqlite:///\"+os.path.join(DATAPATH, DATA_DB))\". \n",
        "#After this we are reading our csv file in chunks of 150 as an iterator. It simply means that whenever the loop runs we are \n",
        "#simply reading 150 rows everytime and appending this 150 rows in the sqlite database created above in the table name \"Rows\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxw_nO_i6_d_"
      },
      "source": [
        "if os.path.isfile(os.path.join(DATAPATH, DATA_DB)):\n",
        "    start = datetime.now()\n",
        "    connection = sqlite3.connect(os.path.join(DATAPATH, DATA_DB))\n",
        "    data_count = pd.read_sql_query(\"SELECT COUNT(*) FROM Rows\", connection)\n",
        "    connection.close()\n",
        "    print(\"Total number of rows in database = {}\".format(data_count[\"COUNT(*)\"][0]))\n",
        "    print(\"Time taken to run this cell :\", datetime.now() - start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDOFcyqI6_dH"
      },
      "source": [
        "if os.path.isfile(os.path.join(DATAPATH, DATA_DB)):\n",
        "    start = datetime.now()\n",
        "    connection = sqlite3.connect(os.path.join(DATAPATH, DATA_DB))\n",
        "    data_dup = pd.read_sql_query(\"SELECT Title, Body, Tags, COUNT(*) as Count_Dup FROM Rows GROUP BY Title, Body, Tags\", connection)\n",
        "    connection.close()\n",
        "    print(\"Time taken to run this cell : {}\".format(datetime.now() - start))\n",
        "#In this cell, this above sql command will group the title, body and tags where all of them are similar and then it will count\n",
        "#their occurances."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv7ynCFw7MtP"
      },
      "source": [
        "data_dup.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-_KS3n77Mov"
      },
      "source": [
        "print(\"Percentage of duplicate data points = {}({}%)\".format((data_count[\"COUNT(*)\"][0]-data_dup.shape[0]), (((data_count[\"COUNT(*)\"][0]-data_dup.shape[0])/data_count[\"COUNT(*)\"][0])*100)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ytznyV7Mn9"
      },
      "source": [
        "data_dup['Count_Dup'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBby_Eem7McQ"
      },
      "source": [
        "if not os.path.isfile(os.path.join(DATAPATH, DATA_DB_DEDUP)):\n",
        "    engine = create_engine(\"sqlite:///\"+os.path.join(DATAPATH, DATA_DB_DEDUP))\n",
        "    data_dup = pd.DataFrame(data_dup, columns=['Title', 'Body', 'Tags'])\n",
        "    data_dup.to_sql(\"no_dup_train\", engine)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV2S682J7Xj7"
      },
      "source": [
        "if os.path.isfile(os.path.join(DATAPATH, DATA_DB_DEDUP)):\n",
        "    con = sqlite3.connect(os.path.join(DATAPATH, DATA_DB_DEDUP))\n",
        "    data_tags = pd.read_sql_query(\"SELECT Tags FROM no_dup_train\", con)\n",
        "    data_tags_count = data_tags[\"Tags\"].apply(lambda x: len(x.split(\" \"))) #series.apply(func) invoke function on values of Series.\n",
        "    data_tags['Tags_Count'] = data_tags_count\n",
        "    data_tags.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoGPzSTy7XjJ"
      },
      "source": [
        "print(\"Maximum number of tags per question = \"+str(max(data_tags['Tags_Count'])))\n",
        "print(\"Minimum number of tags per question = \"+str(min(data_tags['Tags_Count'])))\n",
        "print(\"Avg number of tags per question = \"+str(sum(data_tags['Tags_Count'])/len(data_tags['Tags_Count'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV2Jed507Xf5"
      },
      "source": [
        "fig = plt.figure(figsize = (8, 6))\n",
        "axes = fig.add_axes([0.1,0.1,1,1])\n",
        "axes.set_title(\"Distribution of Tags per Question\", fontsize = 20)\n",
        "axes.set_xlabel(\"Tags\", fontsize = 20)\n",
        "axes.set_ylabel(\"Count\", fontsize = 20)\n",
        "plt.grid(linestyle='-', linewidth=0.5)\n",
        "axes.tick_params(labelsize = 15)\n",
        "sns.countplot(list(data_tags['Tags_Count']), ax = axes)\n",
        "for i in axes.patches:\n",
        "    axes.text(i.get_x()+0.09, i.get_height()+9500, str(round(i.get_height(), 2)), fontsize=16, color='black')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLf03X-87XfG"
      },
      "source": [
        "data_tags['Tags_Count'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9-_VVtP7h8W"
      },
      "source": [
        "#above cell shows that most of the data points have 3 tags then 2 tags and so on.\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CZqnIJe9XG2"
      },
      "source": [
        "\n",
        "#Observations:\n",
        "\n",
        "    #Maximum number of tags per question: 5\n",
        "    #Minimum number of tags per question: 1\n",
        "    #Avg. number of tags per question: 2.899\n",
        "    #Most of the questions are having 2 or 3 tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "586BJ7v57h7n"
      },
      "source": [
        "if os.path.isfile(os.path.join(DATAPATH, DATA_DB_DEDUP)):\n",
        "    con = sqlite3.connect(os.path.join(DATAPATH, DATA_DB_DEDUP))\n",
        "    data_tags = pd.read_sql_query(\"SELECT Tags FROM no_dup_train\", con)\n",
        "    vectorizer = CountVectorizer(tokenizer = lambda x: x.split(\" \"))\n",
        "    data_bow = vectorizer.fit_transform(data_tags['Tags'])\n",
        "    con.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIXETdhY7h4S"
      },
      "source": [
        "print(\"Total number of datapoints = {}\".format(data_bow.shape[0]))\n",
        "print(\"Total number of unique tags = {}\".format(data_bow.shape[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL91nDdh7h3b"
      },
      "source": [
        "print(\"Some of the tags in our data: {}\".format(vectorizer.get_feature_names()[:15]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzqZ_wEg700N"
      },
      "source": [
        "\n",
        "\n",
        "#top 10 highest occurring tags\n",
        "col_sum = data_bow.sum(axis = 0).A1 #data_bow.sum(axis = 0) will sum the column of sparse matrix then .A1 will convert that \n",
        "                                    #matrix into array.\n",
        "feat_count = dict(zip(vectorizer.get_feature_names(), col_sum))\n",
        "feat_count_sorted = dict(sorted(feat_count.items(), key = lambda x: x[1], reverse = True))\n",
        "count_data = {\"Tags\":list(feat_count_sorted.keys()), \"Count\": list(feat_count_sorted.values())}\n",
        "count_df = pd.DataFrame(data = count_data)\n",
        "count_df[:10]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teYKYbID70zb"
      },
      "source": [
        "worcloudPlot = WordCloud(background_color=\"black\", width=1500, height=1000)\n",
        "worcloudPlot.generate_from_frequencies(frequencies=feat_count)\n",
        "plt.figure(figsize=(30,20))\n",
        "plt.imshow(worcloudPlot, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FkR9SRD8HTk"
      },
      "source": [
        "axes = count_df.head(20).plot(x = 'Tags', y = 'Count', kind = 'bar', figsize = (18, 10), fontsize = 15, grid = True)\n",
        "plt.xlabel(\"\")\n",
        "plt.ylabel(\"Count\", fontsize = 20)\n",
        "plt.title(\"Top 20 Highest occurring Tags\", fontsize = 20)\n",
        "cnt = 0\n",
        "for i in axes.patches:\n",
        "    axes.text(i.get_x(), i.get_height()+2000, count_df.head(20)['Tags'][cnt], fontsize=12, color='black')\n",
        "    cnt +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMyOGo49TFZ"
      },
      "source": [
        "\n",
        "#Observations:\n",
        "\n",
        "    #Majority of the most frequent tags are programming language.\n",
        "    # C# is the top most frequent programming language.\n",
        "    #Android, IOS, Linux and windows are among the top most frequent operating systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x3cdFSn8HP0"
      },
      "source": [
        "frequency_tags = list(feat_count_sorted.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIEeifUN8HOz"
      },
      "source": [
        "plt.figure(figsize = (8, 6))\n",
        "plt.plot(frequency_tags)\n",
        "plt.title(\"Tag Numbers VS Frequency\", fontsize=20)\n",
        "plt.xlabel(\"Tag Numbers\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\", fontsize=15)\n",
        "plt.grid(linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XFEjYmP8bPf"
      },
      "source": [
        "\n",
        "\n",
        "Above plot shows that there are very few tags whose frequency is very high, however, there are many tags whose frequency is very low.\n",
        "So, we will now plot the first 1000 most frequently occurring tags.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB-XT3oJ8K-7"
      },
      "source": [
        "plt.figure(figsize = (8, 6))\n",
        "plt.plot(frequency_tags[:1000])\n",
        "plt.title(\"Tag Numbers VS Frequency(First 1000)\", fontsize=20)\n",
        "plt.xlabel(\"Tag Numbers\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\", fontsize=15)\n",
        "plt.grid(linestyle='-', linewidth=0.5)\n",
        "print(frequency_tags[0:1000:25])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDNa9Osk8imE"
      },
      "source": [
        "\n",
        "\n",
        "Even from above plot we are not be able to know how many tags are there whose occurrances are high?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcPsVjdR8K6p"
      },
      "source": [
        "plt.figure(figsize = (8, 6))\n",
        "plt.plot(frequency_tags[:100])\n",
        "plt.title(\"Tag Numbers VS Frequency(First 100)\", fontsize=20)\n",
        "plt.xlabel(\"Tag Numbers\", fontsize=15)\n",
        "plt.ylabel(\"Frequency\", fontsize=15)\n",
        "plt.grid(linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkYsgIh38K5o"
      },
      "source": [
        "print(frequency_tags[0:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4joUIbv8rsT"
      },
      "source": [
        "\n",
        "\n",
        "From above plot we can easily observe that first 20 tags are occurring more than 50k times. 100th tag is occurring approx 13k times.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOx4_EQB8m9B"
      },
      "source": [
        "fig = plt.figure(figsize = (10, 6))\n",
        "\n",
        "axes = fig.add_axes([0.1,0.1,1,1])\n",
        "axes.set_title(\"Quantile values of Tag Number VS Frequency\", fontsize = 20)\n",
        "axes.set_xlabel(\"Quantiles\", fontsize = 20)\n",
        "axes.set_ylabel(\"Frequency\", fontsize = 20)\n",
        "axes.plot(frequency_tags[0:100])\n",
        "\n",
        "plt.scatter(x = np.arange(0, 100, 5), y = frequency_tags[0:100][::5], c = \"blue\", s = 70, label=\"quantiles with 0.05 intervals\")\n",
        "plt.scatter(x = np.arange(0, 100, 25), y = frequency_tags[0:100][::25], c = \"red\", s = 70, label=\"quantiles with 0.25 intervals\")\n",
        "plt.legend(loc='upper right', fontsize = 20)\n",
        "\n",
        "for x, y in zip(np.arange(0, 100, 25), frequency_tags[0:100][::25]):\n",
        "    plt.annotate(s = '({},{})'.format(x, y), xy = (x, y), fontweight='bold', fontsize = 16, xytext=(x-1, y+5500))\n",
        "    \n",
        "axes.tick_params(labelsize = 15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sROF_3xE8m8c"
      },
      "source": [
        "print(\"Number of tags occurring in more than 10k datapoints = {}\".format(count_df[count_df['Count']>10000].shape[0]))\n",
        "print(\"Number of tags occurring in more than 100k datapoints = {}\".format(count_df[count_df['Count']>100000].shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXTtbMRr9N93"
      },
      "source": [
        "\n",
        "#Observations:\n",
        "\n",
        "    #There are 153 tags which are occurring in more than 10k datapoints.\n",
        "    #There are 14 tags which are occurring in more than 100k datapoints.\n",
        "    #Most frequent tag is c# which is occurring in 331505 datapoints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQSYd_4j9N6D"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NppB40E98m3u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzEEjbui9AQo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKnZ7wvj9AP2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwPeR4ji9AMX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY3IYueT9ALV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}